Multiple Linear Regression
========================================================
author: 
date: 12/5/2018
autosize: true

Multiple Linear Regression
========================================================

MLR is used when we want to build a model with more than one variable  

_This is singular LR and models a line._
$$
y_i = \beta_0 +  \beta_i x_i + \epsilon_i i = 1,...,n
$$

_This is a MLR model that descrbies a parabola_
$$
y_i = \beta_0 +  \beta_i x_1 + \beta_2 x_2 + \epsilon_i i = 1,...,n
$$

Chapter 8 Problem 3
========================================================

_This is a single row of data_
```{r echo= FALSE}
row <- as.data.frame(cbind(120, 285, 0, 27, 62, 100, 0)) 
colnames(row) <- c("bwt", "ges", "par", "age", "ht", "wt", "sk")
row
```
_This is the model resulting from said data_
```{r echo = FALSE}
intercept <- c(-80.41, 14.35, -5.60, 0.0000)
gestation <- c(.44, .03, 15.26, 0)
parity <- c(-3.33, 1.13, -2.95, .0033)
age <- c(-.01, .09, -.1, .9170)
height <- c(1.15, .21, 5.63, 0.0000)
weight <- c(.05, .03, 1.99, .0471)
smoke <- c(-8.40, .95, -8.81, 0.000)
df <- rbind(intercept, gestation, parity, age, height, weight, smoke)
df <- as.data.frame(df)
colnames(df) <- c("est", "std er", "t", "p")
df
```

The model (part a).
========================================================

_Our model is built from the coefficient column of that data_


$$
y_i = -8041 +  .44 x_1   -3.33x_2 - .01x_3 + 1.15 x_4 + .05 x_5 -8.40 x_6+ \epsilon_i
$$

Slopes (part b)
========================================================

 This slope represents the average increase in $y$ over $x$  
 
**Gestation**: the average birthweight increases by .44 ounces per day of pregnacy  

**AGE**: The average birth weight decreease by about 3.33 ounces per year of the mother's age

What about parity? (part c)
========================================================
The coefficient for parity in the previous exercise was -1.93. 

These coefficients are different because **our** model includes more variables.

Does it check out? (part d)
========================================================

To calculate the residual, we can use R right here in the presentation! 
_This is the value predicted by our model_
```{r echo = FALSE}
y.pred = -80.41 +  .44 *284   -3.33*0 - .01*27 + 1.15*62 + .05*100-8.40*0
y.pred
```
_To find the residual, we subtract the predicted y value from the actual y value._
```{r echo = FALSE}
y.actual = 120
residual = y.actual -y.pred
residual
```
Hey! That's pretty good. 

Variance of Residuals (part 3)
========================================================

To calculate the residual, we can use R right here in the presentation!  
_This is the value predicted by our model_
```{r }
var.e = 249.28
var.y = 332.57
pop = 1236
k = 6
r.square = 1-(var.e/var.y)
r.square.adjusted = 1 -(var.e/var.y) * (pop-1/pop-k-1)
r.square
r.square.adjusted
```

